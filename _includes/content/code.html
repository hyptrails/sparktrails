<h2>Quickstart</h2>
<p>
	In this section we give a quickstart tutorial on how to get and use SparkTrails.
	SparkTrails is implemented for <a href="https://spark.apache.org">Apache Spark</a>
	and is written in <a href="http://www.scala-lang.org/">Scala</a>.
	Thus, the relevant code snippets are mostly in Scala.
	For more details, also see the <a href="https://github.com/mgbckr/sparktrails/">GitHub page</a>
</p>

<p>
	Get and build SparkTrails:
</p>

{% highlight shell %}
# clone SparkTrails repository
git clone https://github.com/hyptrails/sparktrails-core

# change to repository directory
cd sparktrails

# build and package SparkTrails using Maven
mvn package
{% endhighlight %}

<p>
	Get Spark and run the Spark Shell including SparkTrails:
</p>
{% highlight shell %}
# download Spark
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.2-bin-hadoop2.6.tgz

# unpack Spark
tar -xf spark-1.5.2-bin-hadoop2.6.tgz

# run the shell
./spark-1.5.2-bin-hadoop2.6/bin/spark-shell --jars target/sparktrails-core_2.10-1.0.0.jar
{% endhighlight %}

<p>
	Run our first example:
</p>
{% highlight scala %}
// imports
import org.dmir.sparktrails.Matrix._
import org.dmir.sparktrails.MatrixUtils
import org.dmir.sparktrails.HypTrails
import org.dmir.sparktrails.row.MarkovChainK
import java.io.PrintWriter

// set the number of states
val numberOfStates = 4

// define prefix for files
val prefix = "src/main/resources/tutorial/quickstart"

// load the transition count matrix
val d = MatrixUtils.loadRowMatrix(s"$prefix/transitioncounts.row")(sc)

// load hypotheses
val h1 = MatrixUtils.loadRowMatrix(s"$prefix/hypothesis1.row")(sc)
val h2 = MatrixUtils.loadRowMatrix(s"$prefix/hypothesis2.row")(sc)

// define the concentration parameters to use
val ks = Seq[Double](1,2,3,4,5,10,100,1000,10000)

// elicit prior parameters
val h1Elicited = HypTrails.Prior.elicit(h1.toMapRows, ks)
val h2Elicited = HypTrails.Prior.elicit(h2.toMapRows, ks)

// calculate the log of the marginal likelihood
// for each hypothesis and each k
val e1 = MarkovChainK.evidence(numberOfStates, ks.size, d, h1Elicited)(sc)
val e2 = MarkovChainK.evidence(numberOfStates, ks.size, d, h2Elicited)(sc)

// output results
import java.io.PrintWriter
val pw = new PrintWriter("results.csv")
pw.append(s"hypothesis,k,evidence\n")
ks.zip(e1).foreach { case (k,e) =>
  pw.append(s"h1,$k,$e\n")
}
ks.zip(e2).foreach { case (k,e) =>
  pw.append(s"h2,$k,$e\n")
}
pw.close
{% endhighlight %}

You can plot the results for example using R:
{% highlight R %}
# read evidence values
e <- read.csv("results.csv")

# plot evidence curves
library(ggplot2)
ggplot(e, aes(x = k, y = evidence, colour = hypothesis)) + geom_point() + geom_line()
{% endhighlight %}

<p>
For additional examples, we refer to the SparkTrails repository
where we will successively add more tutorials.
</p>
