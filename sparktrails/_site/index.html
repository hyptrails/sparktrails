<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>SparkTrails | A MapReduce implementation of HypTrails</title>
    <meta name="description" content="SparkTrails is a MapReduce implementation of HypTrails and enables fast, scalable and distributed comparison of hypotheses about human trails. 
">

    <link rel="stylesheet" href="/sparktrails/lib/bootstrap-3.3.6/css/bootstrap.min.css">
    <link rel="stylesheet" href="/sparktrails/css/main.css">
    <link rel="stylesheet" href="/sparktrails/css/syntax.css">
    <link rel="canonical" href="https://sparktrails.github.io/sparktrails//">
</head>


  <body>

    <!-- Fixed navbar -->
<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="#">SparkTrails</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li><a href="#quickstart">Quickstart</a></li>
        <li class="dropdown"><a href="#evaluation">Evaluation</a>
        </li>
        <li><a href="#authors">Authors</a></li>
        <li><a href="#contact">Contact</a></li>
<!--         <li class="dropdown">
          <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Dropdown <span class="caret"></span></a>
          <ul class="dropdown-menu">
            <li><a href="#">Action</a></li>
            <li><a href="#">Another action</a></li>
            <li><a href="#">Something else here</a></li>
            <li role="separator" class="divider"></li>
            <li class="dropdown-header">Nav header</li>
            <li><a href="#">Separated link</a></li>
            <li><a href="#">One more separated link</a></li>
          </ul>
        </li> -->
      </ul>
<!--       <ul class="nav navbar-nav navbar-right">
        <li><a href="../navbar/">Default</a></li>
        <li><a href="../navbar-static-top/">Static top</a></li>
        <li class="active"><a href="./">Fixed top <span class="sr-only">(current)</span></a></li>
      </ul> -->
    </div><!--/.nav-collapse -->
  </div>
</nav>
    <!-- <header class="site-header">
</header> -->


	<div class="content">
    	<div class="container">
	<a class="anchor" id="about"></a>
	<div class="page-header">
		<h1>SparkTrails</h1>
		<p class="lead">SparkTrails is a MapReduce implementation of HypTrails based on <a href="http://spark.apache.org/">Apache Spark</a> and enables fast, scalable and distributed comparison of hypotheses about human trails.</p>
	</div>
	<p>
		For a primer, we refer to the paper introducing SparkTrails and as well as the original HypTrails paper.
		In the following 
			we give additional details on the SparkTrails and how to use it,
			and elaborate on the evaluation we have conducted in the SparkTrails paper.
	</p>
	<div class="publications">
		<ul>
			<li class="details">
				<b>Martin Becker, Hauke Mewes, Andreas Hotho, Dimitar Dimitrov, Florian Lemmerich, Markus Strohmaier</b><br/>
				<a href="http://dmir.org/pub/2016/sparktrails.pdf">SparkTrails: A MapReduce Implementation of HypTrails for Comparing Hypotheses About Human Trails</a><br/>
				<i>Proceedings of the 25th International Conference on World Wide Web, 2016</i>
			</li>
			<li class="details">
				<b>Philipp Singer, Denis Helic, Andreas Hotho, Markus Strohmaier</b><br/>
				<a href="http://www.www2015.it/documents/proceedings/proceedings/p1003.pdf">HypTrails: A Bayesian Approach for Comparing Hypotheses About Human Trails on the Web</a><br/>
				<i>Proceedings of the 24th International Conference on World Wide Web, 2015</i>
			</li>
		</ul>
	</div>
</div>

<div class="container">
	<a class="anchor" id="quickstart"></a>
	<h2>Quickstart</h2>
<p>
	In this section we give a quickstart tutorial on how to get and use SparkTrails.
	SparkTrails is implemented for <a href="https://spark.apache.org">Apache Spark</a>
	and is written in <a href="http://www.scala-lang.org/">Scala</a>.
	Thus, the relevant code snippets are mostly in Scala.
	For more details, also see the <a href="https://github.com/hyptrails/sparktrails-core/">GitHub page</a>
</p>

<p>
	Get and build SparkTrails:
</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># clone SparkTrails repository</span>
git clone https://github.com/hyptrails/sparktrails-core

<span class="c"># change to repository directory</span>
<span class="nb">cd </span>sparktrails

<span class="c"># build and package SparkTrails using Maven</span>
mvn package</code></pre></figure>

<p>
	Get Spark and run the Spark Shell including SparkTrails:
</p>
<figure class="highlight"><pre><code class="language-shell" data-lang="shell"><span class="c"># download Spark</span>
wget http://d3kbcqa49mib13.cloudfront.net/spark-1.5.2-bin-hadoop2.6.tgz

<span class="c"># unpack Spark</span>
tar -xf spark-1.5.2-bin-hadoop2.6.tgz

<span class="c"># run the shell</span>
./spark-1.5.2-bin-hadoop2.6/bin/spark-shell --jars target/sparktrails-core_2.10-1.0.0.jar</code></pre></figure>

<p>
	Run our first example:
</p>
<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="c1">// imports
</span><span class="k">import</span> <span class="nn">org.dmir.sparktrails.Matrix._</span>
<span class="k">import</span> <span class="nn">org.dmir.sparktrails.MatrixUtils</span>
<span class="k">import</span> <span class="nn">org.dmir.sparktrails.HypTrails</span>
<span class="k">import</span> <span class="nn">org.dmir.sparktrails.row.MarkovChainK</span>
<span class="k">import</span> <span class="nn">java.io.PrintWriter</span>

<span class="c1">// set the number of states
</span><span class="k">val</span> <span class="n">numberOfStates</span> <span class="k">=</span> <span class="mi">4</span>

<span class="c1">// define prefix for files
</span><span class="k">val</span> <span class="n">prefix</span> <span class="k">=</span> <span class="s">"src/main/resources/tutorial/quickstart"</span>

<span class="c1">// load the transition count matrix
</span><span class="k">val</span> <span class="n">d</span> <span class="k">=</span> <span class="nc">MatrixUtils</span><span class="o">.</span><span class="n">loadRowMatrix</span><span class="o">(</span><span class="n">s</span><span class="s">"$prefix/transitioncounts.row"</span><span class="o">)(</span><span class="n">sc</span><span class="o">)</span>

<span class="c1">// load hypotheses
</span><span class="k">val</span> <span class="n">h1</span> <span class="k">=</span> <span class="nc">MatrixUtils</span><span class="o">.</span><span class="n">loadRowMatrix</span><span class="o">(</span><span class="n">s</span><span class="s">"$prefix/hypothesis1.row"</span><span class="o">)(</span><span class="n">sc</span><span class="o">)</span>
<span class="k">val</span> <span class="n">h2</span> <span class="k">=</span> <span class="nc">MatrixUtils</span><span class="o">.</span><span class="n">loadRowMatrix</span><span class="o">(</span><span class="n">s</span><span class="s">"$prefix/hypothesis2.row"</span><span class="o">)(</span><span class="n">sc</span><span class="o">)</span>

<span class="c1">// define the concentration parameters to use
</span><span class="k">val</span> <span class="n">ks</span> <span class="k">=</span> <span class="nc">Seq</span><span class="o">[</span><span class="kt">Double</span><span class="o">](</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">10</span><span class="o">,</span><span class="mi">100</span><span class="o">,</span><span class="mi">1000</span><span class="o">,</span><span class="mi">10000</span><span class="o">)</span>

<span class="c1">// elicit prior parameters
</span><span class="k">val</span> <span class="n">h1Elicited</span> <span class="k">=</span> <span class="nc">HypTrails</span><span class="o">.</span><span class="nc">Prior</span><span class="o">.</span><span class="n">elicit</span><span class="o">(</span><span class="n">h1</span><span class="o">.</span><span class="n">toMapRows</span><span class="o">,</span> <span class="n">ks</span><span class="o">)</span>
<span class="k">val</span> <span class="n">h2Elicited</span> <span class="k">=</span> <span class="nc">HypTrails</span><span class="o">.</span><span class="nc">Prior</span><span class="o">.</span><span class="n">elicit</span><span class="o">(</span><span class="n">h2</span><span class="o">.</span><span class="n">toMapRows</span><span class="o">,</span> <span class="n">ks</span><span class="o">)</span>

<span class="c1">// calculate the log of the marginal likelihood
// for each hypothesis and each k
</span><span class="k">val</span> <span class="n">e1</span> <span class="k">=</span> <span class="nc">MarkovChainK</span><span class="o">.</span><span class="n">evidence</span><span class="o">(</span><span class="n">numberOfStates</span><span class="o">,</span> <span class="n">ks</span><span class="o">.</span><span class="n">size</span><span class="o">,</span> <span class="n">d</span><span class="o">,</span> <span class="n">h1Elicited</span><span class="o">)(</span><span class="n">sc</span><span class="o">)</span>
<span class="k">val</span> <span class="n">e2</span> <span class="k">=</span> <span class="nc">MarkovChainK</span><span class="o">.</span><span class="n">evidence</span><span class="o">(</span><span class="n">numberOfStates</span><span class="o">,</span> <span class="n">ks</span><span class="o">.</span><span class="n">size</span><span class="o">,</span> <span class="n">d</span><span class="o">,</span> <span class="n">h2Elicited</span><span class="o">)(</span><span class="n">sc</span><span class="o">)</span>

<span class="c1">// output results
</span><span class="k">import</span> <span class="nn">java.io.PrintWriter</span>
<span class="k">val</span> <span class="n">pw</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">PrintWriter</span><span class="o">(</span><span class="s">"results.csv"</span><span class="o">)</span>
<span class="n">pw</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">s</span><span class="s">"hypothesis,k,evidence\n"</span><span class="o">)</span>
<span class="n">ks</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">e1</span><span class="o">).</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span><span class="n">e</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">pw</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">s</span><span class="s">"h1,$k,$e\n"</span><span class="o">)</span>
<span class="o">}</span>
<span class="n">ks</span><span class="o">.</span><span class="n">zip</span><span class="o">(</span><span class="n">e2</span><span class="o">).</span><span class="n">foreach</span> <span class="o">{</span> <span class="k">case</span> <span class="o">(</span><span class="n">k</span><span class="o">,</span><span class="n">e</span><span class="o">)</span> <span class="k">=&gt;</span>
  <span class="n">pw</span><span class="o">.</span><span class="n">append</span><span class="o">(</span><span class="n">s</span><span class="s">"h2,$k,$e\n"</span><span class="o">)</span>
<span class="o">}</span>
<span class="n">pw</span><span class="o">.</span><span class="n">close</span></code></pre></figure>

You can plot the results for example using R:
<figure class="highlight"><pre><code class="language-r" data-lang="r"><span class="c1"># read evidence values
</span><span class="n">e</span> <span class="o">&lt;-</span> <span class="n">read.csv</span><span class="p">(</span><span class="s2">"results.csv"</span><span class="p">)</span>

<span class="c1"># plot evidence curves
</span><span class="n">library</span><span class="p">(</span><span class="n">ggplot2</span><span class="p">)</span>
<span class="n">ggplot</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">k</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">evidence</span><span class="p">,</span> <span class="n">colour</span> <span class="o">=</span> <span class="n">hypothesis</span><span class="p">))</span> <span class="o">+</span> <span class="n">geom_point</span><span class="p">()</span> <span class="o">+</span> <span class="n">geom_line</span><span class="p">()</span></code></pre></figure>

<p>
For additional examples, we refer to the SparkTrails repository
where we will successively add more tutorials.
</p>

</div>

<div class="container">
	<a class="anchor" id="evaluation"></a>
    
<h2>Evaluation</h2>
<p>
	For a general evaluation we refer to the SparkTrails paper.
	In this section we elaborate on the datasets used for runtime experiments as
	well as the baseline code.
</p>
<div class="publications">
	<ul>
		<li class="details">
			<b>Martin Becker, Hauke Mewes, Andreas Hotho, Dimitar Dimitrov, Florian Lemmerich, Markus Strohmaier</b><br/>
			<a href="http://dmir.org/pub/2016/sparktrails.pdf">SparkTrails: A MapReduce Implementation of HypTrails for Comparing Hypotheses About Human Trails</a><br/>
			<i>Proceedings of the 25th International Conference on World Wide Web, 2016</i>
		</li>
	</ul>
</div>

<h3>Datasets</h3>
<p>
	In the SparkTrails paper, we use several datasets to evaluate the 
	runtime of our approach.
	This includes several synthetic datasets, a Wikipedia dataset and a Flickr dataset 
	aimed at demonstrating the scalability of SparkTrails.
	In this section we elaborate on these datasets.
</p>
<p>
	Generally, HypTrails works with trails on a finite set of states
	in a Markov chain scenario of order 1.
	Thus, each evaluation dataset is made up of two matrices: 
	an <strong>observation matrix</strong> and a <strong>hypothesis matrix</strong>.
	The observation matrix contains the number observation for each state transition
	and the hypothesis matrix contains the transition probabilities between states
	according to a user hypothesis. 
</p>


<h4>Synthetic Datasets</h4>
<p>
	Generally we use synthetic datasets because we can easily scale their size.
	Additionally, we can identify the characteristics of SparkTrails with regard to
	the sparsity of the given datasets. 
	Thus, overall, we work with two types synthetic datasets:
	dense datasets and a sparse datasets.
	Both are generated randomly.
	The general procedure is as follows:
</p>
<ol>
	<li>
		Define the number of states for the datasets, a seed for
		the pseudo-random generator and an upper limit for
		the observation count.
	</li>
	<li>
		Create a list with all the states and assign a pseudo-random 
		number, a state seed, to each state, using the
		seed from step 1.
	</li>
	<li>
		For each state, create another list with all the states
		and assign a pseudo-random value between 1 and the
		upper limit specified in step 1 to each of them, using
		the state seed from step 2.
	</li>
</ol>
<p>
	With this approach, we get a dense observation matrix, i.e., 
	a matrix with no zero entries.
	However, since typical datasets are usually sparse, 
	i.e., there are a lot of entries equals to zero, 
	we need a way to imitate this characteristic. 
	Hence, we introduce a so called <em>row fraction</em> and <em>column fraction</em>. 
	The row fraction is used to determine the count of non-zero rows in
	our observation matrix, the column fraction to determine
	the number of non-zero entries in the remaining rows. 
	Both are used as a probability for each row/column to be zero or
	not and are applied before iterating through the list of the
	states in step 2/3.
</p>

<h5>Dense Datasets</h5>
<p>
	The dense datasets (<em>s<sub>1</sub> and s<sub>2</sub></em>) 
	use dense observation and hypothesis matrices created as described above.
	For <em>s<sub>1</sub></em> we use 93000 states and 
	for <em>s<sub>2</sub></em> we use 186000 states.
	In both cases we use a single generated matrix as both
	<strong>observation and hypothesis matrix</strong>.
</p>

<h5>Sparse Datasets</h5>
<p>
	The sparse dataset (<em>r</em>) is randomly created using
	<em>row fraction</em> and <em>column fraction</em> as described above.
	We use 26350000 states and a row as well as a column fraction of 1%.
	Note that while this is very sparse, the fractions still
	larger than for example for the Wikipedia dataset.
	Again we use a single generated matrix as both
	<strong>observation and hypothesis matrix</strong>.
	In the sparse case this represents the worst case with regard to
	runtime since SparkTrails takes advantage of the general sparisty
	structure as described in the corresponding paper.
</p>
<h4>Wikipedia Dataset</h4>
<p>
	The Wikipedia datasets (<em>w<sub>self</sub> and w<sub>nw</sub></em>) is based on transitions between Wikipedia articles.
</p>
<p>
	The <strong>observation matrix</strong> for both datasets (<em>w<sub>self</sub> and w<sub>nw</sub></em>)
	contains transition counts extracted from the logs of 
	the desktop version of Wikipedia from Feb 2015 [1] by Wulczyn and Taraborelli.
	Log entries identified to be from spiders and bots are not included.
	Transition that occur less than 10 times in the logs are removed.
	The dataset contains transitions with articles from the main namespace 
	as but also includes incoming traffic from external sources.
	For our experiments, we discard the latter.
</p>
<p>
	For the "self" dataset (<em>w<sub>self</sub></em>), we reuse the observation matrix
	as <strong>hypothesis matrix</strong>.
</p>
<p>
	For the network dataset (<em>w<sub>nw</sub></em>), the <strong>hypothesis matrix</strong> 
	uses the underlying link network created from the links between the articles 
	in the XML Dump of the English Wikipedia from 4<sup>th</sup> of March 2015.
	The transition probability between a state <em>i</em> and a state <em>j</em>
	is equal to 0 if there is no link and 1 over the number of outgoing links of state <em>i</em> otherwise.
</p>

<div class="publications">
	<ul>
		<li class="details">
			[1] <b>Ellery Wulczyn, Dario Taraborelli</b><br/>
			<a href="https://datahub.io/dataset/wikipedia-clickstream/resource/be85cc68-d1e6-4134-804a-fd36b94dbb82">Wikipedia clickstream</a><br/>
			<i>figshare, 2015 (accessed: 2015-12-13)</i>
		</li>
	</ul>
</div>

<h4>Flickr Dataset</h4>
<p>
	For the Flickr dataset (<em>f</em>), we consider phototrails of individual Flickr users.
	The dataset we use is based on the "Photowalking the city" paper by Becker et al. [1].
	In particular, we use the Los Angeles observation matrix and the proximity hypothesis with a 
	spreading parameter of 2.5km.
</p>
<p>
	The <strong>observation matrix</strong> is generated by dividing the city area
	into cells of 200m by 200m and counting the transitions between these grid cells
	with regard to photo sequences generated by individual Flickr users.
</p>
<p>
	For the <strong>hypothesis matrix</strong>, the transition matrix is based on proximity.
	That is, the transition probability between a state <em>i</em> and a state <em>j</em>
	is small, if the distance between these two states is large:
	P(j|i) = 1/Z &middot; e<sup>−1 / (2&sigma;<sup>2</sup>) &middot; dist(i, j)<sup>2</sup></sup>.
</p>

<div class="publications">
	<ul>
		<li class="details">
			[1] <b>Martin Becker, Philipp Singer, Florian Lemmerich, Andreas Hotho, Denis Helic, Markus Strohmaier</b><br/>
			<a href="http://www.is.informatik.uni-wuerzburg.de/mitarbeiter/becker_martin/?tx_extbibsonomycsl_publicationlist%5Bcontroller%5D=Document&tx_extbibsonomycsl_publicationlist%5BintraHash%5D=95dff057c4b86fc4b2307b5405c36193&tx_extbibsonomycsl_publicationlist%5BfileName%5D=Becker_2015_Photowalking.pdf&tx_extbibsonomycsl_publicationlist%5BuserName%5D=becker&tx_extbibsonomycsl_publicationlist%5Bpreview%5D=LARGE&tx_extbibsonomycsl_publicationlist%5Baction%5D=download&cHash=db0deca366f99f117a2b10f0010334f8">Photowalking the city: comparing hypotheses about urban photo trails on Flickr</a><br/>
			<i>Social Informatics, Volume 9471 of the series Lecture Notes in Computer Science, 2015</i>
		</li>
	</ul>
</div>

<h3>Baselines</h3>
While a <a href="https://github.com/psinger/HypTrails">standard Python implementation</a> exists,
we use a custom, simplified Python implementation as a baseline.
The original implementation is flexible with regard to several special cases
and allows to use specialized storage mechanisms for large observation and hypothesis matrices.
However, in our evaluation scenario, we found this implementation to be slow 
in comparison to our custom, simplified version.
Thus, for evaluating SparkTrails, we use this simplified version,
which will be available on GitHub.
<!-- which is available <a href="">on GitHub</a>. -->


	
</div>

<div class="container">
	<a class="anchor" id="authors"></a>
    <h2>Authors</h2>
<ul>
	<li>
		<strong>Martin Becker</strong><br/>
		University of Würzburg<br/>
		<a href="http://www.is.informatik.uni-wuerzburg.de/staff/becker/">http://www.is.informatik.uni-wuerzburg.de/staff/becker</a>
	</li>
	
	
	<li>
		<strong>Hauke Mewes</strong><br/>
		University of Würzburg<br/>
	</li>
	
		
	<li>
		<strong>Andreas Hotho</strong><br/>
		University of Würzburg<br/>
		<a href="http://www.is.informatik.uni-wuerzburg.de/staff/hotho/">http://www.is.informatik.uni-wuerzburg.de/staff/hotho/</a>
	</li>
		
	<li>
		<strong>Dimitar Dimitrov</strong><br/>
		GESIS - Leibniz Institute for the Social Sciences<br/>
		<a href="http://www.dimitardimitrov.info">http://www.dimitardimitrov.info</a>
	</li>
	
	<li>
		<strong>Florian Lemmerich</strong><br/>
		GESIS - Leibniz Institute for the Social Sciences<br/>
		<a href="http://www.is.informatik.uni-wuerzburg.de/staff/lemmerich/">http://www.is.informatik.uni-wuerzburg.de/staff/lemmerich/</a>
	</li>
		
	<li>
		<strong>Markus Strohmaier</strong><br/>
		GESIS - Leibniz Institute for the Social Sciences and University of Koblenz-Landau<br/>
		<a href="http://www.gesis.org/das-institut/mitarbeiterverzeichnis/?name=markus%2Cstrohmaier">http://www.gesis.org/das-institut/mitarbeiterverzeichnis/?name=markus%2Cstrohmaier</a>
	</li>
</ul>
</div>

<div class="container">
	<a class="anchor" id="contact"></a>
    <h2>Contact</h2>
<p class="lead">Contact us for further information.</p>
<ul>
	<li>
		Martin Becker<br/>
		<a href="mailto:becker@informatik.uni-wuerzburg.de">becker@informatik.uni-wuerzburg.de</a>
	</li>
</ul>
</div>
    </div>

    <footer class="site-footer">
	<div class="placeholder"></div>
</footer>

    <script type="text/javascript" src="/sparktrails//lib/jquery-1.11.3/jquery.min.js"></script>
<script type="text/javascript" src="/sparktrails//lib/bootstrap-3.3.6/js/bootstrap.min.js"></script>
<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

  </body>

</html>
